import os, tempfile, requests, logging, asyncio, re, hashlib
from datetime import datetime
from typing import List, Dict, Optional
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ApplicationBuilder, MessageHandler, CommandHandler, ContextTypes, filters, ConversationHandler, CallbackQueryHandler

# ================== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø­Ø³Ù†Ø© ==================
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
MAX_LINES = 200000
CHUNK_SIZE = 5000
SUPPORTED_LARGE_EXTENSIONS = {'.py', '.js', '.java', '.cpp', '.c', '.txt', '.log', '.csv', '.json', '.xml', '.html', '.css', '.php', '.rb', '.go', '.rs', '.ts', '.sql'}

# ================== Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ==================
WAITING_TOKEN, WAITING_FILE, WAITING_INSTRUCTIONS, WAITING_BACKEND_CHOICE = range(4)

# ================== Ù†Ù…Ø§Ø°Ø¬ Ù…Ø­Ø³Ù†Ø© Ù…Ø¹ ØªÙˆÙƒÙ†Ø§Øª ÙØ¹Ù„ÙŠØ© ==================
BACKEND_KEYS = {
    "KIMI": {
        "key": "sk-your-kimi-token-here",  # ğŸ”¹ Ø§Ø³ØªØ¨Ø¯Ù„ Ø¨Ø§Ù„ØªÙˆÙƒÙŠÙ† Ø§Ù„ÙØ¹Ù„ÙŠ
        "base": "https://api.moonshot.cn/v1",
        "models": ["moonshot-v1-8k", "moonshot-v1-32k", "moonshot-v1-128k"],
        "context": 128000
    },
    "DEEPSEEK": {
        "key": "sk-your-deepseek-token-here",  # ğŸ”¹ Ø§Ø³ØªØ¨Ø¯Ù„ Ø¨Ø§Ù„ØªÙˆÙƒÙŠÙ† Ø§Ù„ÙØ¹Ù„ÙŠ
        "base": "https://api.deepseek.com",
        "models": ["deepseek-chat", "deepseek-coder"],
        "context": 64000
    },
    "CHATGPT": {
        "key": "sk-your-openai-token-here",  # ğŸ”¹ Ø§Ø³ØªØ¨Ø¯Ù„ Ø¨Ø§Ù„ØªÙˆÙƒÙŠÙ† Ø§Ù„ÙØ¹Ù„ÙŠ
        "base": "https://api.openai.com",
        "models": ["gpt-4", "gpt-3.5-turbo"],
        "context": 128000
    }
}

user_sessions = {}
file_history = {}

# ================== Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© Ù…Ø­Ø³Ù†Ø© ==================
def validate_token(token: str) -> bool:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© ØªÙˆÙƒÙ† Ø§Ù„Ø¨ÙˆØª"""
    pattern = r'^\d+:[A-Za-z0-9_-]+$'
    return bool(re.match(pattern, token))

def sanitize_filename(filename: str) -> str:
    """ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ù…Ù† Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø®Ø·Ø±Ø©"""
    return re.sub(r'[^\w\-_.]', '_', filename)

def detect_language(filename: str) -> str:
    """ÙƒØ´Ù Ù„ØºØ© Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© Ù…Ù† Ø§Ù…ØªØ¯Ø§Ø¯ Ø§Ù„Ù…Ù„Ù"""
    ext_lang_map = {
        '.py': 'Python', '.js': 'JavaScript', '.java': 'Java',
        '.cpp': 'C++', '.c': 'C', '.html': 'HTML', '.css': 'CSS',
        '.php': 'PHP', '.rb': 'Ruby', '.go': 'Go', '.rs': 'Rust',
        '.ts': 'TypeScript', '.sql': 'SQL', '.json': 'JSON',
        '.xml': 'XML', '.csv': 'CSV', '.txt': 'Text'
    }
    ext = os.path.splitext(filename)[1].lower()
    return ext_lang_map.get(ext, 'Ù†Øµ Ø¹Ø§Ø¯ÙŠ')

def create_backup(user_id: int, filename: str, content: str) -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ø­Ø³Ù†Ø©"""
    backup_dir = f"backups/{user_id}"
    os.makedirs(backup_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_filename = sanitize_filename(filename)
    backup_file = f"{backup_dir}/{safe_filename}_{timestamp}.bak"
    
    try:
        with open(backup_file, 'w', encoding='utf-8') as f:
            f.write(content)
        return backup_file
    except Exception as e:
        logging.error(f"Backup failed: {e}")
        return ""

def validate_backend_keys() -> Dict[str, bool]:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© ØªÙˆÙƒÙ†Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
    validation_results = {}
    
    for name, config in BACKEND_KEYS.items():
        if config["key"].startswith("sk-your-"):
            validation_results[name] = False
            logging.warning(f"âŒ {name}: ØªÙˆÙƒÙ† ØºÙŠØ± Ù…Ø¶Ø¨ÙˆØ·")
        else:
            validation_results[name] = True
            logging.info(f"âœ… {name}: Ø§Ù„ØªÙˆÙƒÙ† Ø¬Ø§Ù‡Ø²")
    
    return validation_results

# ================== Ù†Ø¸Ø§Ù… Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù† ==================
async def call_backend_advanced(name: str, filename: str, text: str, instructions: str, model: str = None) -> Dict:
    """Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ù…ØªÙ‚Ø¯Ù… Ù…Ø­Ø³Ù† Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
    if name not in BACKEND_KEYS:
        return {
            "success": False,
            "error": f"Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {name} ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…",
            "content": f"âŒ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {name} ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…"
        }
    
    info = BACKEND_KEYS[name]
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙˆÙƒÙ†
    if info["key"].startswith("sk-your-"):
        return {
            "success": False,
            "error": f"ØªÙˆÙƒÙ† {name} ØºÙŠØ± Ù…Ø¶Ø¨ÙˆØ·",
            "content": f"âŒ ÙŠØ±Ø¬Ù‰ Ø¶Ø¨Ø· ØªÙˆÙƒÙ† {name} Ø£ÙˆÙ„Ø§Ù‹"
        }
    
    if model is None:
        model = info["models"][0]
    
    # Ø¥ØµÙ„Ø§Ø­ Ù…Ø³Ø§Ø± API
    if name == "CHATGPT":
        url = f"{info['base']}/v1/chat/completions"
    else:
        url = f"{info['base']}/chat/completions"
    
    system_prompt = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø¨Ø±Ù…Ø¬ÙŠ Ø®Ø¨ÙŠØ±. Ø§Ù„Ù…Ù„Ù: {filename} - Ø§Ù„Ù„ØºØ©: {detect_language(filename)}

Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª: {instructions}

Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø­Ø§Ù„ÙŠ ÙˆÙÙ‡Ù… Ù‡ÙŠÙƒÙ„Ù‡
2. ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©
3. Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ù†Ù…Ø· Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„Ø£ØµÙ„ÙŠ
4. Ø¥Ø¶Ø§ÙØ© ØªØ¹Ù„ÙŠÙ‚Ø§Øª ØªÙˆØ¶ÙŠØ­ÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©
5. Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø´ÙŠÙØ±Ø© Ù…Ù† Ø§Ù„Ù†Ø§Ø­ÙŠØ© Ø§Ù„ÙˆØ¸ÙŠÙÙŠØ©
6. Ø§Ù‚ØªØ±Ø§Ø­ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ø°Ø§Øª ØµÙ„Ø©

Ø£Ø¹Ø¯ Ø§Ù„Ø´ÙŠÙØ±Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø© ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† Ø´Ø±Ø­ Ø¥Ø¶Ø§ÙÙŠ:"""
    
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"```{detect_language(filename).lower()}\n{text}\n```"}
        ],
        "temperature": 0.1,
        "max_tokens": min(info["context"] - 1000, 32000),
        "top_p": 0.9,
        "frequency_penalty": 0.1,
        "presence_penalty": 0.1
    }
    
    headers = {
        "Authorization": f"Bearer {info['key']}", 
        "Content-Type": "application/json",
        "User-Agent": "AdvancedCodeBot/3.0"
    }
    
    try:
        async with asyncio.timeout(120):  # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ÙˆÙ‚Øª Ù„Ù…Ù†Ø§ÙˆÙ„Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
            response = requests.post(url, headers=headers, json=payload, timeout=120)
            response.raise_for_status()
            result = response.json()
            
            content = result.get("choices", [{}])[0].get("message", {}).get("content", "")
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø´ÙŠÙØ±Ø© Ù…Ù† markdown code blocks Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª
            code_blocks = re.findall(r'```(?:\w+)?\n(.*?)\n```', content, re.DOTALL)
            if code_blocks:
                content = code_blocks[0]
            else:
                # Ø¥Ø°Ø§ Ù„Ù… ØªÙˆØ¬Ø¯ code blocksØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙƒÙ…Ø§ Ù‡Ùˆ
                content = content.strip()
            
            return {
                "success": True,
                "content": content,
                "model_used": model,
                "tokens_used": result.get("usage", {}).get("total_tokens", 0)
            }
    except asyncio.TimeoutError:
        logging.error(f"Timeout calling {name}")
        return {
            "success": False,
            "error": "Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø·Ù„Ø¨",
            "content": f"âŒ {name}: Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø·Ù„Ø¨ (120 Ø«Ø§Ù†ÙŠØ©)"
        }
    except Exception as e:
        logging.error(f"Error calling {name}: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "content": f"âŒ Ø®Ø·Ø£ ÙÙŠ {name}: {str(e)}"
        }

# ================== Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø© ==================
class AdvancedFileProcessor:
    def __init__(self):
        self.chunks = []
        self.current_chunk = 0
    
    def split_file(self, content: str, chunk_size: int = CHUNK_SIZE) -> List[str]:
        """ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ ØµØºÙŠØ±Ø© Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚"""
        lines = content.split('\n')
        total_lines = len(lines)
        
        chunks = []
        for i in range(0, total_lines, chunk_size):
            # Ø¥Ø¶Ø§ÙØ© ØªØ¯Ø§Ø®Ù„ Ø¨Ø³ÙŠØ· Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚
            start = max(0, i - 10)  # 10 Ø£Ø³Ø·Ø± Ø³Ø§Ø¨Ù‚Ø© Ù„Ù„Ø³ÙŠØ§Ù‚
            end = min(total_lines, i + chunk_size + 10)  # 10 Ø£Ø³Ø·Ø± Ù„Ø§Ø­Ù‚Ø© Ù„Ù„Ø³ÙŠØ§Ù‚
            
            chunk = '\n'.join(lines[start:end])
            chunks.append({
                'content': chunk,
                'start_line': start + 1,
                'end_line': end,
                'is_context': i != start
            })
        
        return chunks
    
    def analyze_file_complexity(self, content: str) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ù…Ù„Ù"""
        lines = content.split('\n')
        total_lines = len(lines)
        total_chars = len(content)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        code_lines = [line for line in lines if line.strip() and not line.strip().startswith('#')]
        comment_lines = [line for line in lines if line.strip().startswith('#') or '//' in line]
        
        return {
            "total_lines": total_lines,
            "total_chars": total_chars,
            "code_lines": len(code_lines),
            "comment_lines": len(comment_lines),
            "comment_ratio": len(comment_lines) / max(total_lines, 1),
            "estimated_chunks": (total_lines + CHUNK_SIZE - 1) // CHUNK_SIZE,
            "avg_line_length": total_chars / max(total_lines, 1),
            "file_hash": hashlib.md5(content.encode()).hexdigest()[:12],
            "complexity": "Ø¹Ø§Ù„ÙŠØ©" if total_lines > 10000 else "Ù…ØªÙˆØ³Ø·Ø©" if total_lines > 1000 else "Ù…Ù†Ø®ÙØ¶Ø©"
        }

# ================== ÙˆØ§Ø¬Ù‡Ø© Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø­Ø³Ù†Ø© ==================
async def start_advanced(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    """Ø¨Ø¯Ø¡ Ù…Ø­Ø§Ø¯Ø«Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù…Ø­Ø³Ù†Ø©"""
    user = update.effective_user
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    available_backends = validate_backend_keys()
    active_backends = [name for name, valid in available_backends.items() if valid]
    
    if not active_backends:
        await update.message.reply_text(
            "âŒ **Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†Ù…Ø§Ø°Ø¬ Ù…ØªØ§Ø­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹**\n\n"
            "ÙŠØ¬Ø¨ Ø¶Ø¨Ø· ØªÙˆÙƒÙ†Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙÙŠ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø£ÙˆÙ„Ø§Ù‹.\n"
            "ØªÙˆÙƒÙ†Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø­Ø§Ù„ÙŠØ© ØºÙŠØ± Ù…Ø¶Ø¨ÙˆØ·Ø© Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­.",
            parse_mode='Markdown'
        )
        return ConversationHandler.END
    
    # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ§Ø¬Ù‡Ø© Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    keyboard = []
    for backend in active_backends:
        emoji = "âœ…" if available_backends[backend] else "âŒ"
        keyboard.append([InlineKeyboardButton(f"{emoji} {backend}", callback_data=f"backend_{backend}")])
    
    if len(active_backends) > 1:
        keyboard.append([InlineKeyboardButton("ğŸš€ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©", callback_data="backend_all")])
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.message.reply_text(
        f"ğŸ› ï¸ **Ù…Ø±Ø­Ø¨Ø§Ù‹ {user.first_name} ÙÙŠ Ø¨ÙˆØª Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…!**\n\n"
        f"ğŸ“Š **Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø© ({len(active_backends)}):**\n"
        f"Ø§Ø®ØªØ± Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ:",
        reply_markup=reply_markup,
        parse_mode='Markdown'
    )
    return WAITING_BACKEND_CHOICE

async def receive_file_enhanced(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    """Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ù…Ù„ÙØ§Øª Ù…Ø­Ø³Ù‘Ù† Ù…Ø¹ ØªØ­Ù„ÙŠÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ"""
    msg = update.message
    user_id = update.effective_user.id
    
    if not msg.document:
        await msg.reply_text("âŒ ÙŠØ±Ø¬Ù‰ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù ÙƒÙ€ Document.")
        return WAITING_FILE
    
    file_size = msg.document.file_size or 0
    
    if file_size > MAX_FILE_SIZE:
        await msg.reply_text(
            f"âŒ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù ÙƒØ¨ÙŠØ± Ø¬Ø¯Ø§Ù‹! ({file_size//1024//1024}MB)\n"
            f"Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰: {MAX_FILE_SIZE//1024//1024}MB"
        )
        return WAITING_FILE
    
    filename = msg.document.file_name or "unnamed_file"
    file_ext = os.path.splitext(filename)[1].lower()
    
    # ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù…Ù„Ù
    processor = AdvancedFileProcessor()
    
    try:
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù…Ø¹ Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„ØªÙ‚Ø¯Ù…
        progress_msg = await msg.reply_text("ğŸ“¥ **Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù...**")
        
        file = await ctx.bot.get_file(msg.document.file_id)
        with tempfile.TemporaryDirectory() as tmp:
            path = os.path.join(tmp, sanitize_filename(filename))
            await file.download_to_drive(custom_path=path)
            
            await progress_msg.edit_text("ğŸ” **Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ù...**")
            
            with open(path, "r", encoding="utf-8", errors="ignore") as fh:
                original_content = fh.read()
        
        # ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù…Ù„Ù
        analysis = processor.analyze_file_complexity(original_content)
        
        # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø©
        user_sessions[user_id]["file"] = {
            "filename": filename,
            "content": original_content,
            "language": detect_language(filename),
            "size": len(original_content),
            "lines": analysis["total_lines"],
            "backup_path": create_backup(user_id, filename, original_content),
            "analysis": analysis,
            "complexity": analysis["complexity"]
        }
        
        file_info = user_sessions[user_id]["file"]
        
        # Ø¥Ø±Ø³Ø§Ù„ ØªØ­Ù„ÙŠÙ„ Ù…ÙØµÙ„
        response_text = f"""
ğŸ‰ **ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­!** {'ğŸš€' if analysis['complexity'] == 'Ø¹Ø§Ù„ÙŠØ©' else 'ğŸ“Š'}

ğŸ“„ **Ø§Ù„Ù…Ù„Ù:** `{filename}`
ğŸ”¤ **Ø§Ù„Ù„ØºØ©:** {file_info['language']}
ğŸ“ˆ **Ø§Ù„Ø­Ø¬Ù…:** {analysis['total_lines']:,} Ø³Ø·Ø± â€¢ {analysis['total_chars']:,} Ø­Ø±Ù
ğŸ·ï¸ **Ø§Ù„ØªØ¹Ù‚ÙŠØ¯:** {analysis['complexity']}
ğŸ§® **Ø§Ù„Ø¨ØµÙ…Ø©:** `{analysis['file_hash']}`

ğŸ“Š **ØªØ­Ù„ÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠ:**
â€¢ Ø£Ø³Ø·Ø± ÙƒÙˆØ¯: {analysis['code_lines']:,}
â€¢ Ø£Ø³Ø·Ø± ØªØ¹Ù„ÙŠÙ‚Ø§Øª: {analysis['comment_lines']:,}
â€¢ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª: {analysis['comment_ratio']:.1%}

ğŸ’¡ **Ø§ÙƒØªØ¨ Ø§Ù„Ø¢Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ ØªØ·Ø¨ÙŠÙ‚Ù‡Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù:**
        """
        
        if analysis["total_lines"] > 10000:
            response_text += f"\nâ³ **Ù…Ù„Ø§Ø­Ø¸Ø©:** Ø§Ù„Ù…Ù„Ù ÙƒØ¨ÙŠØ± Ø¬Ø¯Ø§Ù‹ØŒ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù‚Ø¯ ØªØ³ØªØºØ±Ù‚ Ø¹Ø¯Ø© Ø¯Ù‚Ø§Ø¦Ù‚."
        
        await progress_msg.edit_text(response_text, parse_mode='Markdown')
        return WAITING_INSTRUCTIONS
        
    except Exception as e:
        logging.error(f"File processing error: {e}")
        await update.message.reply_text(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: {str(e)}")
        return WAITING_FILE

# ================== Ø£ÙˆØ§Ù…Ø± Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ø­Ø³Ù†Ø© ==================
async def setup_command(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    """Ø¹Ø±Ø¶ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø­Ø§Ù„ÙŠØ©"""
    validation = validate_backend_keys()
    
    setup_text = "âš™ï¸ **Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø­Ø§Ù„ÙŠØ©:**\n\n"
    
    for name, config in BACKEND_KEYS.items():
        status = "âœ… Ø¬Ø§Ù‡Ø²" if validation[name] else "âŒ ÙŠØ­ØªØ§Ø¬ Ø¥Ø¹Ø¯Ø§Ø¯"
        models = ", ".join(config["models"])
        
        setup_text += f"**{name}:** {status}\n"
        setup_text += f"   â€¢ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {models}\n"
        setup_text += f"   â€¢ Ø§Ù„Ø³ÙŠØ§Ù‚: {config['context']:,} Ø±Ù…Ø²\n\n"
    
    setup_text += "ğŸ”§ Ù„Ø¶Ø¨Ø· Ø§Ù„ØªÙˆÙƒÙ†Ø§ØªØŒ Ù‚Ù… Ø¨ØªØ¹Ø¯ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø¨ÙˆØª Ù…Ø¨Ø§Ø´Ø±Ø©."
    
    await update.message.reply_text(setup_text, parse_mode='Markdown')

async def help_enhanced(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    """ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù…Ø­Ø³Ù†Ø©"""
    help_text = """
ğŸ› ï¸ **Ø¨ÙˆØª Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù… - Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª**

ğŸ“ **Ø§Ù„Ù…ÙŠØ²Ø§Øª:**
â€¢ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„ÙØ§Øª Ø­ØªÙ‰ 50MB
â€¢ Ø¯Ø¹Ù… 3+ Ù†Ù…Ø§Ø°Ø¬ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
â€¢ Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ ØªÙ„Ù‚Ø§Ø¦ÙŠ
â€¢ ØªØ­Ù„ÙŠÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ù…Ù„ÙØ§Øª

ğŸ¯ **Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù…ØªØ§Ø­Ø©:**
/start - Ø¨Ø¯Ø¡ Ø¬Ù„Ø³Ø© Ø¬Ø¯ÙŠØ¯Ø©
/setup - Ø¹Ø±Ø¶ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬  
/stats - Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ù„Ø³Ø©
/help - Ø¹Ø±Ø¶ Ù‡Ø°Ù‡ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª

ğŸ“ **Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:**
1. Ø§Ø¨Ø¯Ø£ Ø¨Ù€ /start
2. Ø§Ø®ØªØ± Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
3. Ø£Ø±Ø³Ù„ Ø§Ù„Ù…Ù„Ù ÙƒÙ€ Document
4. Ø§ÙƒØªØ¨ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
5. Ø§Ø³ØªÙ„Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ø³Ù†

ğŸ”§ **Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©:** Python, JS, Java, C++, ÙˆØºÙŠØ±Ù‡Ø§
    """
    
    await update.message.reply_text(help_text, parse_mode='Markdown')

# ================== Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ø§Ù„Ù…Ø­Ø³Ù† ==================
def main_enhanced():
    """ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª Ø§Ù„Ù…Ø­Ø³Ù†"""
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ…ÙŠ
    os.makedirs("backups/large_files", exist_ok=True)
    os.makedirs("temp/large_processing", exist_ok=True)
    os.makedirs("logs", exist_ok=True)
    
    # ğŸ”¹ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªÙˆÙƒÙ† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    BOT_TOKEN = "8214334664:AAGWEhTYrFTyN_TCxbFlQfdnIKYLgfI496A"
    
    # ğŸ”¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙˆÙƒÙ†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©
    available_models = validate_backend_keys()
    active_models = [name for name, valid in available_models.items() if valid]
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('logs/bot_enhanced.log'),
            logging.StreamHandler()
        ]
    )
    
    logger = logging.getLogger(__name__)
    
    if not active_models:
        logger.warning("âš ï¸  Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†Ù…Ø§Ø°Ø¬ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ø¶Ø¨ÙˆØ·Ø©!")
    else:
        logger.info(f"ğŸš€ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¬Ø§Ù‡Ø²Ø©: {', '.join(active_models)}")
    
    app = ApplicationBuilder()\
        .token(BOT_TOKEN)\
        .concurrent_updates(True)\
        .pool_timeout(120)\
        .read_timeout(120)\
        .write_timeout(120)\
        .build()

    # Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ù…Ø­Ø³Ù†
    conv_handler = ConversationHandler(
        entry_points=[CommandHandler("start", start_advanced)],
        states={
            WAITING_BACKEND_CHOICE: [CallbackQueryHandler(backend_button_handler, pattern="^backend_")],
            WAITING_FILE: [MessageHandler(filters.Document.ALL, receive_file_enhanced)],
            WAITING_INSTRUCTIONS: [MessageHandler(filters.TEXT & ~filters.COMMAND, receive_instructions_super)]
        },
        fallbacks=[CommandHandler("cancel", cancel)],
        name="enhanced_conv",
        allow_reentry=True
    )

    app.add_handler(conv_handler)
    app.add_handler(CommandHandler("stats", stats_command))
    app.add_handler(CommandHandler("setup", setup_command))
    app.add_handler(CommandHandler("help", help_enhanced))
    app.add_handler(CommandHandler("start", start_advanced))

    logger.info("ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª Ø§Ù„Ù…Ø­Ø³Ù† Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¹Ù…Ù„Ø§Ù‚Ø©...")
    
    try:
        app.run_polling()
    except Exception as e:
        logger.error(f"âŒ ÙØ´Ù„ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª: {e}")
        raise

if __name__ == "__main__":
    main_enhanced()
